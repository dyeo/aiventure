from typing import *
import re

import torch
import random
import numpy

from transformers import GPT2LMHeadModel, GPT2Tokenizer


class AI(object):
    """
    The class responsible for handling raw text-generation using a gpt-2 model.
    """
    def __init__(
            self,
            model_path=None,
            use_gpu=True,
    ):
        assert model_path, "No model specified!"

        self.model_path = str(model_path)
        self.use_gpu = torch.cuda.is_available() and use_gpu
        self.dtype = torch.float16
        self.device = torch.device("cuda" if self.use_gpu else "cpu")

        seed = random.randint(0, 2147483647)
        numpy.random.seed(seed)
        torch.random.manual_seed(seed)

        self.tokenizer = GPT2Tokenizer.from_pretrained(self.model_path)
        self.eos_token_id = self.tokenizer.encode('<|endoftext|>')[0]

        self.model = GPT2LMHeadModel.from_pretrained(self.model_path)
        self.model.to(self.dtype).to(self.device)
        self.model.eval()

    @property
    def model_info(self) -> str:
        return f'{self.dtype} precision model running on {"gpu" if self.use_gpu else "cpu"}'

    def generate(
            self,
            context: str,
            prompt: str,
            max_length: int,
            beam_searches: int,
            temperature: float,
            top_k: float,
            top_p: float,
            repetition_penalty: float,
    ) -> str:
        """
        Generates a raw, unaltered string from a story input.

        :param context: The permanent starting context. This is always included, at the cost of shortening the prompt.
        :param prompt: The inciting prompt. This may lose details from the front if the context is long.
        :param max_length: The maximum length of string to generate.
        :param beam_searches: The number of beam searches to perform.
        :param temperature: The temperature used by the sampling algorithm.
        :param top_k: The top_k value used by the sampling algorithm.
        :param top_p: The top_p value used by the sampling algorithm.
        :param repetition_penalty: The repetition penalty. 1.0 is no penalty.
        :return: An unaltered string generated by the AI.
        """
        input_tokens = self.tokenizer.encode(context)
        prompt_tokens = self.tokenizer.encode(prompt)
        memory = 1024-max_length-len(input_tokens)
        input_tokens.extend(prompt_tokens[-memory:])
        input_ids = torch.tensor([input_tokens], dtype=torch.long, device=self.device)
        input_len = len(input_tokens)
        result = self.model.generate(
            input_ids=input_ids,
            min_length=input_len,
            max_length=input_len+max_length,
            do_sample=True,
            num_beams=beam_searches,
            temperature=temperature,
            top_p=top_p,
            top_k=top_k,
            repetition_penalty=repetition_penalty,
            eos_token_id=self.eos_token_id,
        )
        return self.tokenizer.decode(
            result[0][input_len:],
            clean_up_tokenization_spaces=False,
            skip_special_tokens=True,
        )
